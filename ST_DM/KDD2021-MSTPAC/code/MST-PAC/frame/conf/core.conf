#!/bin/bash 
#core configuration is a valid set to verify user's configuration.
#if user defined var is not in core_configuration the frame 
#should send wanring , exit, or set default var for user

core_all_mode=" train predict monitor "
core_all_platform=" local-cpu local-gpu pserver-local pserver-cpu pserver-gpu slurm hadoop "
core_all_reader=" sync async dataset pyreader datafeed "
#local_env_list="python_bin fluid_bin"
cuda_env_list="CUDA_VISIBLE_DEVICES FLAGS_fraction_of_gpu_memory_to_use"

slurm_env_list='
    data_location
    afs_user
    afs_passwd
    afs_host
    fs_ugi=$afs_user+,+$afs_passwd
    afs_mount_path
    data_path=$afs_mount_path+data/+$dataset_name
    output_path=$afs_mount_path+model/+$model_name+/+$job_name
'

user_defined_modules="datasets:BaseDataset nets:BaseNet"

paddlecloud_env_list='
    data_location
    afs_user
    afs_passwd
    afs_host:fs_name
    fs_ugi=$afs_user+,+$afs_passwd
    afs_mount_path
    afs_remote_mount_point=$train_data_dir
    output_path=$train_data_dir+/../paddle-frame/model/+$model_name+/+$job_name
    code_uri=$train_data_dir+/../paddle-frame/libs/+$dataset_name+/+$job_name+.tar.gz
    job_name
    FLAGS_rpc_deadline=3000000
    FLAGS_rpc_deadline=$rpc_deadline
    k8s_ps_num=$ps_num
    k8s_trainers=$nodes_num
    k8s_gpu_cards=$gpu_per_node_num
    slurm_nodes=$nodes_num
    slurm_task_pnode=$workers_per_node_num
    slurm_gpu_pnode=$gpu_per_node_num
    group_name=$queue_name
    tensorflow_version
    fs_name
    fs_ugi
    output_path
    afs_remote_mount_point
    mount_afs
    afs_local_mount_point
    group_name
    ak
    sk
    k8s_trainers
    k8s_ps_num
    k8s_ps_cores
    k8s_cpu_cores
    k8s_ps_memory
    k8s_memory
    k8s_priority
    wall_time
    k8s_gpu_cards
    train_data_dir
    eval_data_dir
'

# add optional evn list here
option_env_list=" thirdparty_path FLAGS_rpc_deadline "
